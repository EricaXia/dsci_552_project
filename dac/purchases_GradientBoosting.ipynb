{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imposed-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-reservoir",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "auburn-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13972, 29) (6872, 29) (13972,) (6872,)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/X_train.npy', 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "with open('../data/X_test.npy', 'rb') as f:\n",
    "    X_test = np.load(f)\n",
    "with open('../data/y_train.npy', 'rb') as f:\n",
    "    y_train = np.load(f)\n",
    "with open('../data/y_test.npy', 'rb') as f:\n",
    "    y_test = np.load(f)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interracial-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train2.npy', 'rb') as f:\n",
    "    X_train2 = np.load(f)\n",
    "with open('X_test2.npy', 'rb') as f:\n",
    "    X_test2 = np.load(f)\n",
    "with open('X_train3.npy', 'rb') as f:\n",
    "    X_train3 = np.load(f)\n",
    "with open('X_test3.npy', 'rb') as f:\n",
    "    X_test3 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "planned-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Administrative',\n",
    " 'Administrative_Duration',\n",
    " 'Informational',\n",
    " 'Informational_Duration',\n",
    " 'ProductRelated',\n",
    " 'ProductRelated_Duration',\n",
    " 'BounceRates',\n",
    " 'ExitRates',\n",
    " 'PageValues',\n",
    " 'SpecialDay',\n",
    " 'OperatingSystems',\n",
    " 'Browser',\n",
    " 'Region',\n",
    " 'TrafficType',\n",
    " 'Month_Aug',\n",
    " 'Month_Dec',\n",
    " 'Month_Feb',\n",
    " 'Month_Jul',\n",
    " 'Month_June',\n",
    " 'Month_Mar',\n",
    " 'Month_May',\n",
    " 'Month_Nov',\n",
    " 'Month_Oct',\n",
    " 'Month_Sep',\n",
    " 'VisitorType_New_Visitor',\n",
    " 'VisitorType_Other',\n",
    " 'VisitorType_Returning_Visitor',\n",
    " 'Weekend_False',\n",
    " 'Weekend_True',\n",
    " 'Revenue']\n",
    "\n",
    "feature_names = columns\n",
    "feature_names.remove(\"Revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quiet-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=feature_names)\n",
    "X_train = X_train.drop(\"Weekend_False\",axis=1)\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "X_test = X_test.drop(\"Weekend_False\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "medieval-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DF = pd.concat([X_train,X_test])\n",
    "y = np.concatenate((y_train,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-cotton",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "heard-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "upset-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": list(np.linspace(200, 1600, 8, dtype=int)),\n",
    "    \"learning_rate\": [0.15, 0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "    \"max_features\": [\"auto\", \"sqrt\"],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_depth\": [4, 6, 8, None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ancient-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(model,param_dist,X,y):\n",
    "    model_rand = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=100, cv=3, verbose=2, random_state=0, n_jobs=-1)\n",
    "    model_rand.fit(X,y)\n",
    "    best_params = model_rand.best_params_\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "experienced-moscow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "{'n_estimators': 1400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'learning_rate': 0.005}\n"
     ]
    }
   ],
   "source": [
    "best_params = get_best_params(model,param_dist,X_train,y_train)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-clarity",
   "metadata": {},
   "source": [
    "## Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "legitimate-optimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.005, max_depth=None,\n",
       "                           max_features='sqrt', n_estimators=1400)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = GradientBoostingClassifier(**best_params)\n",
    "model_best.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "thousand-filling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9203\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(model_best, X_train, y_train)\n",
    "print(np.round(score.mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "handed-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(model,X,y):\n",
    "    y_pred = model.predict(X)\n",
    "    target_names = ['0: No Revenue', '1: Revenue']\n",
    "    report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "    \n",
    "    print(report)\n",
    "    print(\"Confusion Matrix:\\n\",confusion_matrix(y,y_pred))\n",
    "    print(\"Accuracy: \",accuracy_score(y,y_pred))\n",
    "    print(\"ROC-AUC: \",roc_auc_score(y,model.predict_proba(X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "geological-biography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "0: No Revenue       0.91      0.95      0.93      3436\n",
      "   1: Revenue       0.94      0.91      0.93      3436\n",
      "\n",
      "     accuracy                           0.93      6872\n",
      "    macro avg       0.93      0.93      0.93      6872\n",
      " weighted avg       0.93      0.93      0.93      6872\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3252  184]\n",
      " [ 305 3131]]\n",
      "Accuracy:  0.9288416763678696\n",
      "ROC-AUC:  0.9822820346370214\n"
     ]
    }
   ],
   "source": [
    "get_performance(model_best,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-handy",
   "metadata": {},
   "source": [
    "## Model with Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "intermediate-amateur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.005, max_depth=None,\n",
       "                           max_features='sqrt', n_estimators=1400)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = GradientBoostingClassifier(**best_params)\n",
    "model2.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "naked-decision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "0: No Revenue       0.93      0.94      0.93      3436\n",
      "   1: Revenue       0.94      0.92      0.93      3436\n",
      "\n",
      "     accuracy                           0.93      6872\n",
      "    macro avg       0.93      0.93      0.93      6872\n",
      " weighted avg       0.93      0.93      0.93      6872\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3226  210]\n",
      " [ 261 3175]]\n",
      "Accuracy:  0.9314610011641443\n",
      "ROC-AUC:  0.9838436007974186\n"
     ]
    }
   ],
   "source": [
    "get_performance(model2,X_test2,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-jungle",
   "metadata": {},
   "source": [
    "## Model with Feature Selection and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adopted-exchange",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.005, max_depth=None,\n",
       "                           max_features='sqrt', n_estimators=1400)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = GradientBoostingClassifier(**best_params)\n",
    "model3.fit(X_train3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "armed-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "0: No Revenue       0.93      0.94      0.93      3436\n",
      "   1: Revenue       0.94      0.93      0.93      3436\n",
      "\n",
      "     accuracy                           0.93      6872\n",
      "    macro avg       0.93      0.93      0.93      6872\n",
      " weighted avg       0.93      0.93      0.93      6872\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3224  212]\n",
      " [ 252 3184]]\n",
      "Accuracy:  0.9324796274738067\n",
      "ROC-AUC:  0.983464051113933\n"
     ]
    }
   ],
   "source": [
    "get_performance(model3,X_test3,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
