{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "imposed-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-reservoir",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "auburn-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13972, 29) (6872, 29) (13972,) (6872,)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/X_train.npy', 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "with open('../data/X_test.npy', 'rb') as f:\n",
    "    X_test = np.load(f)\n",
    "with open('../data/y_train.npy', 'rb') as f:\n",
    "    y_train = np.load(f)\n",
    "with open('../data/y_test.npy', 'rb') as f:\n",
    "    y_test = np.load(f)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "searching-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Administrative',\n",
    " 'Administrative_Duration',\n",
    " 'Informational',\n",
    " 'Informational_Duration',\n",
    " 'ProductRelated',\n",
    " 'ProductRelated_Duration',\n",
    " 'BounceRates',\n",
    " 'ExitRates',\n",
    " 'PageValues',\n",
    " 'SpecialDay',\n",
    " 'OperatingSystems',\n",
    " 'Browser',\n",
    " 'Region',\n",
    " 'TrafficType',\n",
    " 'Month_Aug',\n",
    " 'Month_Dec',\n",
    " 'Month_Feb',\n",
    " 'Month_Jul',\n",
    " 'Month_June',\n",
    " 'Month_Mar',\n",
    " 'Month_May',\n",
    " 'Month_Nov',\n",
    " 'Month_Oct',\n",
    " 'Month_Sep',\n",
    " 'VisitorType_New_Visitor',\n",
    " 'VisitorType_Other',\n",
    " 'VisitorType_Returning_Visitor',\n",
    " 'Weekend_False',\n",
    " 'Weekend_True',\n",
    " 'Revenue']\n",
    "\n",
    "feature_names = columns\n",
    "feature_names.remove(\"Revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "removable-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=feature_names)\n",
    "X_train = X_train.drop(\"Weekend_False\",axis=1)\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "X_test = X_test.drop(\"Weekend_False\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-hotel",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "reverse-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "operational-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# Random search of parameters, using cross validation, use all cores\n",
    "model_rand = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=100, cv=3, verbose=2, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "monetary-california",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erinszeto/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 40 is smaller than n_iter=100. Running 40 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=LogisticRegression(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                        'penalty': ['l1', 'l2'],\n",
       "                                        'solver': ['liblinear']},\n",
       "                   random_state=0, verbose=2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rand.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "lonely-negotiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'liblinear', 'penalty': 'l1', 'C': 0.00026366508987303583}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = model_rand.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-copyright",
   "metadata": {},
   "source": [
    "## Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "spare-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.00026366508987303583, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = LogisticRegression(**best_params)\n",
    "\n",
    "model_best.fit(X_train,y_train)  # fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "large-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_scores(model,X,y,scoring=['accuracy','precision','f1','roc_auc'],cv=5):\n",
    "    cv_results = cross_validate(model,X,y,scoring=scoring,cv=cv)\n",
    "    print(\"%s\\n-------------------\" % str(model))\n",
    "    for metric in cv_results:\n",
    "        print(\"%s: %f\" % (metric, np.mean(cv_results[metric])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "floral-upset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8605\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(model_best, X_train, y_train)\n",
    "print(np.round(score.mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "prerequisite-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(model,X,y):\n",
    "    y_pred = model.predict(X)\n",
    "    target_names = ['0: No Revenue', '1: Revenue']\n",
    "    report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "    \n",
    "    print(report)\n",
    "    print(\"Confusion Matrix:\\n\",confusion_matrix(y,y_pred))\n",
    "    print(\"Accuracy: \",accuracy_score(y,y_pred))\n",
    "    print(\"ROC-AUC: \",roc_auc_score(y,model.predict_proba(X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "standing-courage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "0: No Revenue       0.84      0.89      0.86      3436\n",
      "   1: Revenue       0.88      0.83      0.85      3436\n",
      "\n",
      "     accuracy                           0.86      6872\n",
      "    macro avg       0.86      0.86      0.86      6872\n",
      " weighted avg       0.86      0.86      0.86      6872\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3045  391]\n",
      " [ 582 2854]]\n",
      "Accuracy:  0.8584109429569267\n",
      "ROC-AUC:  0.8861682134382103\n"
     ]
    }
   ],
   "source": [
    "get_performance(model_best,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "answering-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calc Prec, Recall, F1 scores on test set\n",
    "# y_pred = model_best.predict(X_test)  # predict on test set\n",
    "# target_names = ['0: No Revenue', '1: Revenue']\n",
    "# report1 = classification_report(y_test, y_pred, target_names=target_names)\n",
    "# print(report1)\n",
    "#report1_df = pd.DataFrame(report1).transpose()\n",
    "# model_name = str(model_rand).strip('()')\n",
    "# report1_df.to_csv(f\"{model_name}_report1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-brighton",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "thorough-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train2.npy', 'rb') as f:\n",
    "    X_train2 = np.load(f)\n",
    "with open('X_test2.npy', 'rb') as f:\n",
    "    X_test2 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "spanish-moses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.00026366508987303583, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model = LogisticRegression(**best_params)\n",
    "LR_model.fit(X_train2,y_train)  # fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "described-bahrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8605\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(LR_model, X_train2, y_train)\n",
    "print(np.round(score.mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "guilty-cardiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "0: No Revenue       0.84      0.89      0.86      3436\n",
      "   1: Revenue       0.88      0.83      0.85      3436\n",
      "\n",
      "     accuracy                           0.86      6872\n",
      "    macro avg       0.86      0.86      0.86      6872\n",
      " weighted avg       0.86      0.86      0.86      6872\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3045  391]\n",
      " [ 582 2854]]\n",
      "Accuracy:  0.8584109429569267\n",
      "ROC-AUC:  0.8861789705928192\n"
     ]
    }
   ],
   "source": [
    "get_performance(LR_model,X_test2,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-proof",
   "metadata": {},
   "source": [
    "## Feature Selection and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "photographic-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train3.npy', 'rb') as f:\n",
    "    X_train3 = np.load(f)\n",
    "with open('X_test3.npy', 'rb') as f:\n",
    "    X_test3 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "recognized-friday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.00026366508987303583, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model2 = LogisticRegression(**best_params)\n",
    "LR_model2.fit(X_train3,y_train)  # fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "answering-rebound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8604\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(LR_model2, X_train3, y_train)\n",
    "print(np.round(score.mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "presidential-treaty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "0: No Revenue       0.84      0.89      0.86      3436\n",
      "   1: Revenue       0.88      0.83      0.85      3436\n",
      "\n",
      "     accuracy                           0.86      6872\n",
      "    macro avg       0.86      0.86      0.86      6872\n",
      " weighted avg       0.86      0.86      0.86      6872\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3045  391]\n",
      " [ 582 2854]]\n",
      "Accuracy:  0.8584109429569267\n",
      "ROC-AUC:  0.8861694839682821\n"
     ]
    }
   ],
   "source": [
    "get_performance(LR_model2,X_test3,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
